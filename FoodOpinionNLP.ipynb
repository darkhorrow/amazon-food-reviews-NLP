{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis NLP de reseñas de alimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148845 entries, 0 to 148844\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Score   148845 non-null  int64 \n",
      " 1   Text    148845 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ReviewsPreprocessingStemming.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148845 entries, 0 to 148844\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Score   148845 non-null  int64 \n",
      " 1   Text    148845 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_l = pd.read_csv('ReviewsPreprocessingLematization.csv')\n",
    "df_l.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de matriz término-documento y clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado mediante Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se divide el conjunto de datos original en entrenamiento, test y validación. También se define una pequeña función que facilitaría el uso de distitnos clasificadores más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 119076, Test size: 29769, Validation size: 29769\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.8)\n",
    "df_train, df_val = train_test_split(df, train_size=0.8)\n",
    "\n",
    "print(f'Train size: {len(df_train)}, Test size: {len(df_test)}, Validation size: {len(df_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with(classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_predicted = classifier.predict(X_test)\n",
    "    return {\n",
    "        'accuracy_score': accuracy_score(y_test, y_predicted),\n",
    "        'recall_score': recall_score(y_test, y_predicted, average='macro'),\n",
    "        'precision_score': precision_score(y_test, y_predicted, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte, se realiza la primera matriz término documento, las cuales representan la frecuencia de las palabras encontradas en los textos. En este caso, se ua CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer()\n",
    "Xtrain = tf_vectorizer.fit_transform(df_train['Text'])\n",
    "Xtest = tf_vectorizer.transform(df_test['Text'])\n",
    "Xval = tf_vectorizer.transform(df_val['Text'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "ytrain = encoder.fit_transform(df_train['Score']) \n",
    "ytest = encoder.transform(df_test['Score'])\n",
    "yval = encoder.transform(df_val['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la clasificación, se consideró el uso de un RandomForest, debido a su buenos resultados en la literatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "results = classify_with(rf, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.6308240115556452,\n",
       " 'recall_score': 0.630429582505654,\n",
       " 'precision_score': 0.6332420949816501}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se realiza la segunda matriz término documento. La diferencia más destacable de TF-IDF con respecto a CountVectorizer es que su representación de las frecuencias está normalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "Xtrain = tfidf_vectorizer.fit_transform(df_train['Text'])\n",
    "Xtest = tfidf_vectorizer.transform(df_test['Text'])\n",
    "Xval = tfidf_vectorizer.transform(df_val['Text'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "ytrain = encoder.fit_transform(df_train['Score'])\n",
    "ytest = encoder.transform(df_test['Score'])\n",
    "yval = encoder.transform(df_val['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "results_tfidf = classify_with(rf_tfidf, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.6308240115556452,\n",
       " 'recall_score': 0.6303646113516179,\n",
       " 'precision_score': 0.6343812713257779}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado mediante lematización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se divide el conjunto de datos original en entrenamiento, test y validación. También se define una pequeña función que facilitaría el uso de distitnos clasificadores más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 119076, Test size: 29769, Validation size: 29769\n"
     ]
    }
   ],
   "source": [
    "df_l_train, df_l_test = train_test_split(df_l, train_size=0.8)\n",
    "df_l_train, df_l_val = train_test_split(df_l, train_size=0.8)\n",
    "\n",
    "print(f'Train size: {len(df_l_train)}, Test size: {len(df_l_test)}, Validation size: {len(df_l_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer()\n",
    "Xtrain = tf_vectorizer.fit_transform(df_l_train['Text'])\n",
    "Xtest = tf_vectorizer.transform(df_l_test['Text'])\n",
    "Xval = tf_vectorizer.transform(df_l_val['Text'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "ytrain = encoder.fit_transform(df_l_train['Score']) \n",
    "ytest = encoder.transform(df_l_test['Score'])\n",
    "yval = encoder.transform(df_l_val['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_l = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "results_l = classify_with(rf_l, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9235782189526017,\n",
       " 'recall_score': 0.9235264100386358,\n",
       " 'precision_score': 0.9240594434649664}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "Xtrain = tfidf_vectorizer.fit_transform(df_l_train['Text'])\n",
    "Xtest = tfidf_vectorizer.transform(df_l_test['Text'])\n",
    "Xval = tfidf_vectorizer.transform(df_l_val['Text'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "ytrain = encoder.fit_transform(df_l_train['Score'])\n",
    "ytest = encoder.transform(df_l_test['Score'])\n",
    "yval = encoder.transform(df_l_val['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf_l = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "results_tfidf_l = classify_with(rf_tfidf_l, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9233766670025866,\n",
       " 'recall_score': 0.9233117543692307,\n",
       " 'precision_score': 0.9240272489312658}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tfidf_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de los resultados obtenidos en este notebook, se pueden realizar las siguientes afirmaciones:\n",
    "\n",
    "- El preprocesado mediante lematización da claramente mejores resultados con respecto al stemming, siendo la precisión de un 92% para el primero y de un 62% para el segundo.\n",
    "- La diferencia de usar la vectorización mediante el CountVectorizer y el TF-IDF es muy poca o nula.\n",
    "- A pesar de no estar reflejado en el notebook, el tiempo de ejecución de RandomForest comparado con SVC es bastante inferior. Este último se tuvo que descartar debido a su larga duración de excución.\n",
    "\n",
    "Por otra parte, cabe destacar que, durante las evaluaciones de distintos hiperparámetros para los clasificadores, no se obtuvo mejoras notables (~1%) con respecto a los definido por defecto. Sin embargo, su tiempo de ejecución si que aumenta considerablemente coomo, por ejemplo, el uso de n_estimators = 100, que tarda 8 minutos, frente a n_estiamtors = 500, que duraba más de 30 minutos.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
